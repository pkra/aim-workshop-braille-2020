<!DOCTYPE html><head>
<meta charset="UTF-8">
<title>Matrix multiplication - Wikipedia</title>























</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Matrix_multiplication rootpage-Matrix_multiplication skin-vector action-view skin-vector-legacy minerva--history-page-action-enabled">
		
		<div></div>
		<div></div>
		
		<div></div>
		
		
		<div lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output">
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Matrix_multiplication_qtl1.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/18/Matrix_multiplication_qtl1.svg/220px-Matrix_multiplication_qtl1.svg.png" decoding="async" width="220" height="124" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/18/Matrix_multiplication_qtl1.svg/330px-Matrix_multiplication_qtl1.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/18/Matrix_multiplication_qtl1.svg/440px-Matrix_multiplication_qtl1.svg.png 2x" data-file-width="620" data-file-height="350"></a>  <div class="thumbcaption">For matrix multiplication, the number of columns in the first matrix must be equal to the number of rows in the second matrix. The result matrix has the number of rows of the first and the number of columns of the second matrix.</div></div></div>
<p>In <a href="/wiki/Mathematics" title="Mathematics">mathematics</a>, <b>matrix multiplication</b> is a <a href="/wiki/Binary_operation" title="Binary operation">binary operation</a> that produces a <a href="/wiki/Matrix_(mathematics)" title="Matrix (mathematics)">matrix</a> from two matrices. For matrix multiplication, the number of columns in the first matrix must be equal to the number of rows in the second matrix. The result matrix, known as the <b>matrix product</b>, has the number of rows of the first and the number of columns of the second matrix.
</p><p>Matrix multiplication was first described by the French mathematician <a href="/wiki/Jacques_Philippe_Marie_Binet" title="Jacques Philippe Marie Binet">Jacques Philippe Marie Binet</a> in 1812,<sup class="reference"><a href="#cite_note-1">[1]</a></sup> to represent the <a href="/wiki/Composition_of_functions" class="mw-redirect" title="Composition of functions">composition</a> of <a href="/wiki/Linear_map" title="Linear map">linear maps</a> that are represented by matrices. Matrix multiplication is thus a basic tool of <a href="/wiki/Linear_algebra" title="Linear algebra">linear algebra</a>, and as such has numerous applications in many areas of mathematics, as well as in <a href="/wiki/Applied_mathematics" title="Applied mathematics">applied mathematics</a>, <a href="/wiki/Statistics" title="Statistics">statistics</a>, <a href="/wiki/Physics" title="Physics">physics</a>, <a href="/wiki/Economics" title="Economics">economics</a>, and <a href="/wiki/Engineering" title="Engineering">engineering</a>.<sup class="reference"><a href="#cite_note-Physics_1991-2">[2]</a></sup><sup class="reference"><a href="#cite_note-3">[3]</a></sup>
Computing matrix products is a central operation in all computational applications of linear algebra. 
</p>
<div class="toc" role="navigation" aria-labelledby="mw-toc-heading"><div class="toctitle" lang="en" dir="ltr"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Notation"><span class="tocnumber">1</span> <span class="toctext">Notation</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Definition"><span class="tocnumber">2</span> <span class="toctext">Definition</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Illustration"><span class="tocnumber">2.1</span> <span class="toctext">Illustration</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-4"><a href="#Fundamental_applications"><span class="tocnumber">3</span> <span class="toctext">Fundamental applications</span></a>
<ul>
<li class="toclevel-2 tocsection-5"><a href="#Linear_maps"><span class="tocnumber">3.1</span> <span class="toctext">Linear maps</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#System_of_linear_equations"><span class="tocnumber">3.2</span> <span class="toctext">System of linear equations</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Dot_product,_bilinear_form_and_inner_product"><span class="tocnumber">3.3</span> <span class="toctext">Dot product, bilinear form and inner product</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-8"><a href="#General_properties"><span class="tocnumber">4</span> <span class="toctext">General properties</span></a>
<ul>
<li class="toclevel-2 tocsection-9"><a href="#Non-commutativity"><span class="tocnumber">4.1</span> <span class="toctext">Non-commutativity</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Distributivity"><span class="tocnumber">4.2</span> <span class="toctext">Distributivity</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#Product_with_a_scalar"><span class="tocnumber">4.3</span> <span class="toctext">Product with a scalar</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="#Transpose"><span class="tocnumber">4.4</span> <span class="toctext">Transpose</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#Complex_conjugate"><span class="tocnumber">4.5</span> <span class="toctext">Complex conjugate</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#Associativity"><span class="tocnumber">4.6</span> <span class="toctext">Associativity</span></a>
<ul>
<li class="toclevel-3 tocsection-15"><a href="#Complexity_is_not_associative"><span class="tocnumber">4.6.1</span> <span class="toctext">Complexity is not associative</span></a></li>
<li class="toclevel-3 tocsection-16"><a href="#Application_to_similarity"><span class="tocnumber">4.6.2</span> <span class="toctext">Application to similarity</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-17"><a href="#Square_matrices"><span class="tocnumber">5</span> <span class="toctext">Square matrices</span></a>
<ul>
<li class="toclevel-2 tocsection-18"><a href="#Powers_of_a_matrix"><span class="tocnumber">5.1</span> <span class="toctext">Powers of a matrix</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-19"><a href="#Abstract_algebra"><span class="tocnumber">6</span> <span class="toctext">Abstract algebra</span></a></li>
<li class="toclevel-1 tocsection-20"><a href="#Computational_complexity"><span class="tocnumber">7</span> <span class="toctext">Computational complexity</span></a>
<ul>
<li class="toclevel-2 tocsection-21"><a href="#Related_complexities"><span class="tocnumber">7.1</span> <span class="toctext">Related complexities</span></a></li>
<li class="toclevel-2 tocsection-22"><a href="#Matrix_inversion,_determinant_and_Gaussian_elimination"><span class="tocnumber">7.2</span> <span class="toctext">Matrix inversion, determinant and Gaussian elimination</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-23"><a href="#See_also"><span class="tocnumber">8</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-24"><a href="#Notes"><span class="tocnumber">9</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1 tocsection-25"><a href="#References"><span class="tocnumber">10</span> <span class="toctext">References</span></a></li>
</ul>
</div>

<h2><span class="mw-headline">Notation</span></h2>
<p>This article will use the following notational conventions: matrices are represented by capital letters in bold, e.g. <span class="texhtml"><b>A</b></span>, <a href="/wiki/Euclidean_vector" title="Euclidean vector">vectors</a> in lowercase bold, e.g. <span class="texhtml"><b>a</b></span>, and entries of vectors and matrices are italic (since they are numbers from a field), e.g. <span class="texhtml"><i>A</i></span> and <span class="texhtml"><i>a</i></span>. <a href="/wiki/Index_notation" title="Index notation">Index notation</a> is often the clearest way to express definitions, and is used as standard in the literature. The <span class="texhtml"><i>i, j</i></span> entry of matrix <span class="texhtml"><b>A</b></span> is indicated by <span class="texhtml">(<b>A</b>)<sub><i>ij</i></sub></span>, <span class="texhtml"><i>A</i><sub><i>ij</i></sub></span> or <span class="texhtml"><i>a</i><sub><i>ij</i></sub></span>, whereas a numerical label (not matrix entries) on a collection of matrices is subscripted only, e.g. <span class="texhtml"><b>A</b><sub>1</sub>, <b>A</b><sub>2</sub></span>, etc.
</p>
<h2><span class="mw-headline">Definition</span></h2>
<p>If <span class="texhtml"><b>A</b></span> is an <span class="texhtml"><i>m</i> × <i>n</i></span> matrix and <span class="texhtml"><b>B</b></span> is an <span class="texhtml"><i>n</i> × <i>p</i></span> matrix,
</p>
<dl><dd><span class="mwe-math-element">⠸⠠⠁⠀⠨⠅⠀⠠⠷⠁⠂⠂⠀⠁⠂⠆⠀⠄⠄⠄⠀⠁⠰⠂⠝⠐⠠⠾⠀⠠⠷⠁⠆⠂⠀⠁⠆⠆⠀⠄⠄⠄⠀⠁⠰⠆⠝⠐⠠⠾⠀⠠⠷⠣⠄⠄⠄⠀⠣⠄⠄⠄⠀⠰⠄⠄⠄⠀⠣⠄⠄⠄⠠⠾⠀⠠⠷⠁⠰⠍⠐⠂⠐⠀⠁⠰⠍⠐⠆⠐⠀⠄⠄⠄⠀⠁⠰⠍⠝⠐⠠⠾⠠⠀⠸⠠⠃⠀⠨⠅⠀⠠⠷⠃⠂⠂⠀⠃⠂⠆⠀⠄⠄⠄⠀⠃⠰⠂⠏⠐⠠⠾⠀⠠⠷⠃⠆⠂⠀⠃⠆⠆⠀⠄⠄⠄⠀⠃⠰⠆⠏⠐⠠⠾⠀⠠⠷⠣⠄⠄⠄⠀⠣⠄⠄⠄⠀⠰⠄⠄⠄⠀⠣⠄⠄⠄⠠⠾⠀⠠⠷⠃⠰⠝⠐⠂⠐⠀⠃⠰⠝⠐⠆⠐⠀⠄⠄⠄⠀⠃⠰⠝⠏⠐⠠⠾</span></dd></dl>
<p>the <i>matrix product</i> <span class="texhtml"><b>C</b> = <b>AB</b></span>  (denoted without multiplication signs or dots) is defined to be the <span class="texhtml"><i>m</i> × <i>p</i></span> matrix<sup class="reference"><a href="#cite_note-4">[4]</a></sup><sup class="reference"><a href="#cite_note-5">[5]</a></sup><sup class="reference"><a href="#cite_note-6">[6]</a></sup><sup class="reference"><a href="#cite_note-7">[7]</a></sup>
</p>
<dl><dd><span class="mwe-math-element">⠸⠠⠉⠀⠨⠅⠀⠠⠷⠉⠂⠂⠀⠉⠂⠆⠀⠄⠄⠄⠀⠉⠰⠂⠏⠐⠠⠾⠀⠠⠷⠉⠆⠂⠀⠉⠆⠆⠀⠄⠄⠄⠀⠉⠰⠆⠏⠐⠠⠾⠀⠠⠷⠣⠄⠄⠄⠀⠣⠄⠄⠄⠀⠰⠄⠄⠄⠀⠣⠄⠄⠄⠠⠾⠀⠠⠷⠉⠰⠍⠐⠂⠐⠀⠉⠰⠍⠐⠆⠐⠀⠄⠄⠄⠀⠉⠰⠍⠏⠠⠾</span></dd></dl>
<p>such that 
</p>
<dl><dd><span class="mwe-math-element">⠉⠰⠊⠚⠐⠀⠨⠅⠀⠁⠰⠊⠐⠂⠐⠃⠰⠂⠚⠐⠬⠁⠰⠊⠐⠆⠐⠃⠰⠆⠚⠐⠬⠄⠄⠄⠬⠁⠰⠊⠝⠐⠃⠰⠝⠚⠐⠀⠨⠅⠀⠐⠨⠠⠎⠩⠅⠀⠨⠅⠀⠼⠂⠣⠝⠻⠁⠰⠊⠅⠐⠃⠰⠅⠚⠐⠠</span></dd></dl>
<p>for <span class="texhtml"><i>i</i> = 1, ..., <i>m</i></span> and <span class="texhtml"><i>j</i> = 1, ..., <i>p</i></span>.
</p><p>That is, the entry <span class="mwe-math-element">⠉⠰⠊⠚</span> of the product is obtained by multiplying term-by-term the entries of the <span class="texhtml mvar" style="font-style:italic;">i</span>th row of <span class="texhtml"><b>A</b></span> and the <span class="texhtml mvar" style="font-style:italic;">j</span>th column of <span class="texhtml"><b>B</b></span>, and summing these <span class="texhtml mvar" style="font-style:italic;">n</span> products. In other words, <span class="mwe-math-element">⠉⠰⠊⠚</span> is the <a href="/wiki/Dot_product" title="Dot product">dot product</a> of the <span class="texhtml mvar" style="font-style:italic;">i</span>th row of <span class="texhtml"><b>A</b></span> and the <span class="texhtml mvar" style="font-style:italic;">j</span>th column of <span class="texhtml"><b>B</b></span>.
</p><p>Therefore, <span class="texhtml"><b>AB</b></span> can also be written as
</p>
<dl><dd><span class="mwe-math-element">⠸⠠⠉⠀⠨⠅⠀⠠⠷⠁⠂⠂⠃⠂⠂⠬⠄⠄⠄⠬⠁⠰⠂⠝⠐⠃⠰⠝⠐⠂⠐⠀⠁⠂⠂⠃⠂⠆⠬⠄⠄⠄⠬⠁⠰⠂⠝⠐⠃⠰⠝⠐⠆⠐⠀⠄⠄⠄⠀⠁⠂⠂⠃⠰⠂⠏⠐⠬⠄⠄⠄⠬⠁⠰⠂⠝⠐⠃⠰⠝⠏⠐⠠⠾⠀⠠⠷⠁⠆⠂⠃⠂⠂⠬⠄⠄⠄⠬⠁⠰⠆⠝⠐⠃⠰⠝⠐⠂⠐⠀⠁⠆⠂⠃⠂⠆⠬⠄⠄⠄⠬⠁⠰⠆⠝⠐⠃⠰⠝⠐⠆⠐⠀⠄⠄⠄⠀⠁⠆⠂⠃⠰⠂⠏⠐⠬⠄⠄⠄⠬⠁⠰⠆⠝⠐⠃⠰⠝⠏⠐⠠⠾⠀⠠⠷⠣⠄⠄⠄⠀⠣⠄⠄⠄⠀⠰⠄⠄⠄⠀⠣⠄⠄⠄⠠⠾⠀⠠⠷⠁⠰⠍⠐⠂⠐⠃⠂⠂⠬⠄⠄⠄⠬⠁⠰⠍⠝⠐⠃⠰⠝⠐⠂⠐⠀⠁⠰⠍⠐⠂⠐⠃⠂⠆⠬⠄⠄⠄⠬⠁⠰⠍⠝⠐⠃⠰⠝⠐⠆⠐⠀⠄⠄⠄⠀⠁⠰⠍⠐⠂⠐⠃⠰⠂⠏⠐⠬⠄⠄⠄⠬⠁⠰⠍⠝⠐⠃⠰⠝⠏⠠⠾</span></dd></dl>
<p>Thus the product <span class="texhtml"><b>AB</b></span> is defined if and only if the number of columns in <span class="texhtml"><b>A</b></span> equals the number of rows in <span class="texhtml"><b>B</b></span>, in this case <span class="texhtml"><i>n</i></span>.
</p><p>Usually the entries are numbers, but they may be any kind of <a href="/wiki/Mathematical_object" title="Mathematical object">mathematical objects</a> for which an addition and a multiplication are defined, that are <a href="/wiki/Associative_property" title="Associative property">associative</a>, and such that the addition is <a href="/wiki/Commutative_property" title="Commutative property">commutative</a>, and the multiplication is <a href="/wiki/Distributive_property" title="Distributive property">distributive</a> with respect to the addition. In particular, the entries may be matrices themselves (see <a href="/wiki/Block_matrix" title="Block matrix">block matrix</a>).
</p>
<h3><span class="mw-headline">Illustration</span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Matrix_multiplication_diagram_2.svg" class="image"><img alt="Matrix multiplication diagram 2.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Matrix_multiplication_diagram_2.svg/220px-Matrix_multiplication_diagram_2.svg.png" decoding="async" width="220" height="193" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Matrix_multiplication_diagram_2.svg/330px-Matrix_multiplication_diagram_2.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Matrix_multiplication_diagram_2.svg/440px-Matrix_multiplication_diagram_2.svg.png 2x" data-file-width="313" data-file-height="275"></a>  <div class="thumbcaption"></div></div></div>
<p>The figure to the right illustrates diagrammatically the product of two matrices <span class="texhtml"><b>A</b></span> and <span class="texhtml"><b>B</b></span>, showing how each intersection in the product matrix corresponds to a row of <span class="texhtml"><b>A</b></span> and a column of <span class="texhtml"><b>B</b></span>.
</p>
<dl><dd><span class="mwe-math-element">⠐⠈⠠⠷⠁⠂⠂⠀⠁⠂⠆⠈⠠⠾⠀⠈⠠⠷⠡⠀⠡⠈⠠⠾⠀⠈⠠⠷⠁⠒⠂⠀⠁⠒⠆⠈⠠⠾⠀⠈⠠⠷⠡⠀⠡⠈⠠⠾⠣⠼⠲⠈⠡⠆⠀⠍⠁⠞⠗⠊⠭⠻⠐⠈⠠⠷⠡⠀⠃⠂⠆⠀⠃⠂⠒⠈⠠⠾⠀⠈⠠⠷⠡⠀⠃⠆⠆⠀⠃⠆⠒⠈⠠⠾⠣⠼⠆⠈⠡⠒⠀⠍⠁⠞⠗⠊⠭⠻⠀⠨⠅⠀⠐⠈⠠⠷⠡⠀⠉⠂⠆⠀⠉⠂⠒⠈⠠⠾⠀⠈⠠⠷⠡⠀⠡⠀⠡⠈⠠⠾⠀⠈⠠⠷⠡⠀⠉⠒⠆⠀⠉⠒⠒⠈⠠⠾⠀⠈⠠⠷⠡⠀⠡⠀⠡⠈⠠⠾⠣⠼⠲⠈⠡⠒⠀⠍⠁⠞⠗⠊⠭⠻</span></dd></dl>
<p>The values at the intersections marked with circles are:
</p>
<dl><dd><span class="mwe-math-element">⠉⠂⠆⠀⠀⠨⠅⠀⠁⠂⠂⠃⠂⠆⠬⠁⠂⠆⠃⠆⠆⠀⠉⠒⠒⠀⠀⠨⠅⠀⠁⠒⠂⠃⠂⠒⠬⠁⠒⠆⠃⠆⠒</span></dd></dl>
<h2><span class="mw-headline">Fundamental applications</span></h2>
<p>Historically, matrix multiplication has been introduced for making easier and clarifying computations in <a href="/wiki/Linear_algebra" title="Linear algebra">linear algebra</a>. This strong relationship between matrix multiplication and linear algebra remains fundamental in all mathematics, as well as in <a href="/wiki/Physics" title="Physics">physics</a>, <a href="/wiki/Engineering" title="Engineering">engineering</a> and <a href="/wiki/Computer_science" title="Computer science">computer science</a>.
</p>
<h3><span class="mw-headline">Linear maps</span></h3>
<p>If a <a href="/wiki/Vector_space" title="Vector space">vector space</a> has a finite <a href="/wiki/Basis_(linear_algebra)" title="Basis (linear algebra)">basis</a>, its vectors are each uniquely represented by a finite <a href="/wiki/Sequence_(mathematics)" class="mw-redirect" title="Sequence (mathematics)">sequence</a> of scalars, called a <a href="/wiki/Coordinate_vector" title="Coordinate vector">coordinate vector</a>, whose elements are the <a href="/wiki/Coordinates" class="mw-redirect" title="Coordinates">coordinates</a> of the vector on the basis. These coordinate vectors form another vector space, which is <a href="/wiki/Isomorphism" title="Isomorphism">isomorphic</a> to the original vector space. A coordinate vector is commonly organized as a <a href="/wiki/Column_matrix" class="mw-redirect" title="Column matrix">column matrix</a> (also called <i>column vector</i>), which is a matrix with only one column. So, a column vector represents both a coordinate vector, and a vector of the original vector space.
</p><p>A <a href="/wiki/Linear_map" title="Linear map">linear map</a> <span class="texhtml mvar" style="font-style:italic;">A</span> from a vector space of dimension <span class="texhtml mvar" style="font-style:italic;">n</span> into a vector space of dimension <span class="texhtml mvar" style="font-style:italic;">m</span> maps a column vector
</p>
<dl><dd><span class="mwe-math-element">⠸⠭⠀⠨⠅⠀⠭⠂⠀⠭⠆⠀⠣⠄⠄⠄⠀⠭⠰⠝</span></dd></dl>
<p>onto the column vector
</p>
<dl><dd><span class="mwe-math-element">⠸⠽⠀⠨⠅⠀⠠⠁⠷⠸⠭⠾⠀⠨⠅⠀⠁⠂⠂⠭⠂⠬⠄⠄⠄⠬⠁⠰⠂⠝⠐⠭⠰⠝⠐⠀⠁⠆⠂⠭⠂⠬⠄⠄⠄⠬⠁⠰⠆⠝⠐⠭⠰⠝⠐⠀⠣⠄⠄⠄⠀⠁⠰⠍⠐⠂⠐⠭⠂⠬⠄⠄⠄⠬⠁⠰⠍⠝⠐⠭⠰⠝⠐⠨⠐</span></dd></dl>
<p>The linear map <span class="texhtml mvar" style="font-style:italic;">A</span> is thus defined by the matrix 
</p>
<dl><dd><dl><dd><span class="mwe-math-element">⠸⠠⠁⠀⠨⠅⠀⠠⠷⠁⠂⠂⠀⠁⠂⠆⠀⠄⠄⠄⠀⠁⠰⠂⠝⠐⠠⠾⠀⠠⠷⠁⠆⠂⠀⠁⠆⠆⠀⠄⠄⠄⠀⠁⠰⠆⠝⠐⠠⠾⠀⠠⠷⠣⠄⠄⠄⠀⠣⠄⠄⠄⠀⠰⠄⠄⠄⠀⠣⠄⠄⠄⠠⠾⠀⠠⠷⠁⠰⠍⠐⠂⠐⠀⠁⠰⠍⠐⠆⠐⠀⠄⠄⠄⠀⠁⠰⠍⠝⠐⠠⠾⠠</span></dd></dl></dd></dl>
<p>and maps the column vector <span class="mwe-math-element">⠸⠭</span> to the matrix product 
</p>
<dl><dd><span class="mwe-math-element">⠸⠽⠀⠨⠅⠀⠸⠠⠁⠸⠭⠨⠐</span></dd></dl>
<p>If <span class="texhtml mvar" style="font-style:italic;">B</span> is another linear map from the preceding vector space of dimension <span class="texhtml mvar" style="font-style:italic;">m</span>, into a vector space of dimension <span class="texhtml mvar" style="font-style:italic;">p</span>, it is represented by a <span class="mwe-math-element">⠏⠈⠡⠍</span> matrix <span class="mwe-math-element">⠸⠠⠃⠨⠐</span> A straightforward computation shows that the matrix of the <a href="/wiki/Function_composition" title="Function composition">composite map</a> <span class="mwe-math-element">⠠⠃⠘⠨⠡⠠⠁</span> is the matrix product <span class="mwe-math-element">⠸⠠⠃⠸⠠⠁⠨⠐</span> The general formula <span class="mwe-math-element">⠷⠠⠃⠘⠨⠡⠠⠁⠾⠷⠸⠭⠾⠀⠨⠅⠀⠠⠃⠷⠠⠁⠷⠸⠭⠾⠾</span>) that defines the function composition is instanced here as a specific case of associativity of matrix product (see <a href="#Associativity">§&nbsp;Associativity</a>, below):
</p>
<dl><dd><span class="mwe-math-element">⠷⠸⠠⠃⠸⠠⠁⠾⠸⠭⠀⠨⠅⠀⠸⠠⠃⠷⠸⠠⠁⠸⠭⠾⠀⠨⠅⠀⠸⠠⠃⠸⠠⠁⠸⠭⠨⠐</span></dd></dl>
<h3><span class="mw-headline">System of linear equations</span></h3>
<p>The general form of a <a href="/wiki/System_of_linear_equations" title="System of linear equations">system of linear equations</a> is
</p>
<dl><dd><span class="mwe-math-element">⠁⠂⠂⠭⠂⠬⠄⠄⠄⠬⠁⠰⠂⠝⠐⠭⠰⠝⠐⠀⠨⠅⠀⠃⠂⠀⠁⠆⠂⠭⠂⠬⠄⠄⠄⠬⠁⠰⠆⠝⠐⠭⠰⠝⠐⠀⠨⠅⠀⠃⠆⠀⠣⠄⠄⠄⠀⠁⠰⠍⠐⠂⠐⠭⠂⠬⠄⠄⠄⠬⠁⠰⠍⠝⠐⠭⠰⠝⠐⠀⠨⠅⠀⠃⠰⠍⠐⠨⠐</span></dd></dl>
<p>Using same notation as above, such a system is equivalent with the single matrix <a href="/wiki/Equation" title="Equation">equation</a>
</p>
<dl><dd><span class="mwe-math-element">⠸⠠⠁⠸⠭⠀⠨⠅⠀⠸⠃⠨⠐</span></dd></dl>
<h3><span></span><span class="mw-headline">Dot product, bilinear form and inner product</span></h3>
<p>The <a href="/wiki/Dot_product" title="Dot product">dot product</a> of two column vectors is the matrix product 
</p>
<dl><dd><span class="mwe-math-element">⠸⠭⠘⠠⠨⠠⠞⠐⠸⠽⠠</span></dd></dl>
<p>where <span class="mwe-math-element">⠸⠭⠘⠠⠨⠠⠞</span> is the <a href="/wiki/Row_vector" class="mw-redirect" title="Row vector">row vector</a> obtained by <a href="/wiki/Transpose" title="Transpose">transposing</a> <span class="mwe-math-element">⠸⠭</span> and the resulting 1×1 matrix is identified with its unique entry.
</p><p>More generally, any <a href="/wiki/Bilinear_form" title="Bilinear form">bilinear form</a> over a vector space of finite dimension may be expressed as a matrix product
</p>
<dl><dd><span class="mwe-math-element">⠸⠭⠘⠠⠨⠠⠞⠐⠸⠠⠁⠸⠽⠠</span></dd></dl>
<p>and any <a href="/wiki/Inner_product" class="mw-redirect" title="Inner product">inner product</a> may be expressed as 
</p>
<dl><dd><span class="mwe-math-element">⠸⠭⠘⠸⠻⠐⠸⠠⠁⠸⠽⠠</span></dd></dl>
<p>where <span class="mwe-math-element">⠸⠭⠘⠸⠻</span> denotes the <a href="/wiki/Conjugate_transpose" title="Conjugate transpose">conjugate transpose</a> of <span class="mwe-math-element">⠸⠭</span> (conjugate of the transpose, or equivalently transpose of the conjugate).
</p>
<h2><span class="mw-headline">General properties</span></h2>
<p>Matrix multiplication shares some properties with usual <a href="/wiki/Multiplication" title="Multiplication">multiplication</a>. However, matrix multiplication is not defined if the number of columns of the first factor differs from the number of rows of the second factor, and it is <a href="/wiki/Non-commutative" class="mw-redirect" title="Non-commutative">non-commutative</a>, even when the product remains definite after changing the order of the factors.<sup class="reference"><a href="#cite_note-8">[8]</a></sup><sup class="reference"><a href="#cite_note-9">[9]</a></sup>
</p>
<h3><span class="mw-headline">Non-commutativity</span></h3>
<p>An operation is <a href="/wiki/Commutative_property" title="Commutative property">commutative</a> if, given two elements <span class="texhtml"><b>A</b></span> and <span class="texhtml"><b>B</b></span> such that the product <span class="mwe-math-element">⠸⠠⠁⠸⠠⠃</span> is defined, then <span class="mwe-math-element">⠸⠠⠃⠸⠠⠁</span> is also defined, and <span class="mwe-math-element">⠸⠠⠁⠸⠠⠃⠀⠨⠅⠀⠸⠠⠃⠸⠠⠁⠨⠐</span>
</p><p>If <span class="texhtml"><b>A</b></span> and <span class="texhtml"><b>B</b></span> are matrices of respective sizes <span class="mwe-math-element">⠍⠈⠡⠝</span> and <span class="mwe-math-element">⠏⠈⠡⠟</span>, then <span class="mwe-math-element">⠸⠠⠁⠸⠠⠃</span> is defined if <span class="mwe-math-element">⠝⠀⠨⠅⠀⠏</span>, and <span class="mwe-math-element">⠸⠠⠃⠸⠠⠁</span> is defined if <span class="mwe-math-element">⠍⠀⠨⠅⠀⠟</span>. Therefore, if one of the products is defined, the other is not defined in general. If <span class="mwe-math-element">⠍⠀⠨⠅⠀⠟⠀⠌⠨⠅⠀⠝⠀⠨⠅⠀⠏</span>, the two products are defined, but have different sizes; thus they cannot be equal.  Only if <span class="mwe-math-element">⠍⠀⠨⠅⠀⠟⠀⠨⠅⠀⠝⠀⠨⠅⠀⠏</span>, that is if <span class="texhtml"><b>A</b></span> and <span class="texhtml"><b>B</b></span> are <a href="/wiki/Square_matrices" class="mw-redirect" title="Square matrices">square matrices</a> of the same size are both products defined and the same size. Even in this case, one has in general
</p>
<dl><dd><span class="mwe-math-element">⠸⠠⠁⠸⠠⠃⠀⠌⠨⠅⠀⠸⠠⠃⠸⠠⠁⠨⠐</span></dd></dl>
<p>For example
</p>
<dl><dd><span class="mwe-math-element">⠠⠷⠼⠴⠀⠂⠠⠾⠀⠠⠷⠴⠀⠴⠠⠾⠠⠷⠴⠀⠴⠠⠾⠀⠠⠷⠂⠀⠴⠠⠾⠀⠨⠅⠀⠠⠷⠼⠂⠀⠴⠠⠾⠀⠠⠷⠴⠀⠴⠠⠾⠠</span></dd></dl>
<p>but
</p>
<dl><dd><span class="mwe-math-element">⠠⠷⠼⠴⠀⠴⠠⠾⠀⠠⠷⠂⠀⠴⠠⠾⠠⠷⠴⠀⠂⠠⠾⠀⠠⠷⠴⠀⠴⠠⠾⠀⠨⠅⠀⠠⠷⠼⠴⠀⠴⠠⠾⠀⠠⠷⠴⠀⠂⠠⠾⠨⠐</span></dd></dl>
<p>This example may be expanded for showing that, if <span class="texhtml"><b>A</b></span> is a <span class="mwe-math-element">⠝⠈⠡⠝</span> matrix with entries in a <a href="/wiki/Field_(mathematics)" title="Field (mathematics)">field</a> <span class="texhtml mvar" style="font-style:italic;">F</span>, then <span class="mwe-math-element">⠸⠠⠁⠸⠠⠃⠀⠨⠅⠀⠸⠠⠃⠸⠠⠁</span> for every <span class="mwe-math-element">⠝⠈⠡⠝</span> matrix <span class="texhtml"><b>B</b></span> with entries in <span class="texhtml mvar" style="font-style:italic;">F</span>, <a href="/wiki/If_and_only_if" title="If and only if">if and only if</a> <span class="mwe-math-element">⠸⠠⠁⠀⠨⠅⠀⠉⠸⠠⠊</span> where <span class="mwe-math-element">⠉⠀⠈⠑⠀⠠⠋</span>, and <span class="texhtml"><b>I</b></span> is the <span class="mwe-math-element">⠝⠈⠡⠝</span> <a href="/wiki/Identity_matrix" title="Identity matrix">identity matrix</a>. If, instead of a field, the entries are supposed to belong to a <a href="/wiki/Ring_(mathematics)" title="Ring (mathematics)">ring</a>, then one must add the condition that <span class="texhtml mvar" style="font-style:italic;">c</span> belongs to the <a href="/wiki/Center_(ring_theory)" title="Center (ring theory)">center</a> of the ring.
</p><p>One special case where commutativity does occur is when <span class="texhtml"><b>D</b></span> and <span class="texhtml"><b>E</b></span> are two (square) <a href="/wiki/Diagonal_matrices" class="mw-redirect" title="Diagonal matrices">diagonal matrices</a> (of the same size); then <span class="texhtml"><b>DE</b> = <b>ED</b></span>. Again, if the matrices are over a general ring rather than a field, the corresponding entries in each must also commute with each other for this to hold.
</p>
<h3><span class="mw-headline">Distributivity</span></h3>
<p>The matrix product is <a href="/wiki/Distributive_property" title="Distributive property">distributive</a> with respect to <a href="/wiki/Matrix_addition" title="Matrix addition">matrix addition</a>. That is, if <span class="texhtml"><b>A</b>, <b>B</b>, <b>C</b>, <b>D</b></span> are matrices of respective sizes <span class="texhtml"><i>m</i> × <i>n</i></span>, <span class="texhtml"><i>n</i> × <i>p</i></span>,  <span class="texhtml"><i>n</i> × <i>p</i></span>, and <span class="texhtml"><i>p</i> × <i>q</i></span>, one has (left distributivity)
</p>
<dl><dd><span class="mwe-math-element">⠸⠠⠁⠷⠸⠠⠃⠬⠸⠠⠉⠾⠀⠨⠅⠀⠸⠠⠁⠸⠠⠃⠬⠸⠠⠁⠸⠠⠉⠠</span></dd></dl>
<p>and (right distributivity)
</p>
<dl><dd><span class="mwe-math-element">⠷⠸⠠⠃⠬⠸⠠⠉⠾⠸⠠⠙⠀⠨⠅⠀⠸⠠⠃⠸⠠⠙⠬⠸⠠⠉⠸⠠⠙⠨⠐</span></dd></dl>
<p>This results from the distributivity for coefficients by 
</p>
<dl><dd><span class="mwe-math-element">⠐⠨⠠⠎⠩⠅⠻⠁⠰⠊⠅⠐⠷⠃⠰⠅⠚⠐⠬⠉⠰⠅⠚⠐⠾⠀⠨⠅⠀⠐⠨⠠⠎⠩⠅⠻⠁⠰⠊⠅⠐⠃⠰⠅⠚⠐⠬⠐⠨⠠⠎⠩⠅⠻⠁⠰⠊⠅⠐⠉⠰⠅⠚</span></dd>
<dd><span class="mwe-math-element">⠐⠨⠠⠎⠩⠅⠻⠷⠃⠰⠊⠅⠐⠬⠉⠰⠊⠅⠐⠾⠙⠰⠅⠚⠐⠀⠨⠅⠀⠐⠨⠠⠎⠩⠅⠻⠃⠰⠊⠅⠐⠙⠰⠅⠚⠐⠬⠐⠨⠠⠎⠩⠅⠻⠉⠰⠊⠅⠐⠙⠰⠅⠚⠐⠨⠐</span></dd></dl>
<h3><span class="mw-headline">Product with a scalar</span></h3>
<p>If <span class="texhtml"><b>A</b></span> is a matrix and <span class="texhtml mvar" style="font-style:italic;">c</span> a scalar, then the matrices <span class="mwe-math-element">⠉⠸⠠⠁</span> and <span class="mwe-math-element">⠸⠠⠁⠉</span> are obtained by left or right multiplying all entries of <span class="texhtml"><b>A</b></span> by <span class="texhtml mvar" style="font-style:italic;">c</span>. If the scalars have the <a href="/wiki/Commutative_property" title="Commutative property">commutative property</a>, then <span class="mwe-math-element">⠉⠸⠠⠁⠀⠨⠅⠀⠸⠠⠁⠉⠨⠐</span>
</p><p>If the product <span class="mwe-math-element">⠸⠠⠁⠸⠠⠃</span> is defined (that is the number of columns of <span class="texhtml"><b>A</b></span> equals the number of rows of <span class="texhtml"><b>B</b></span>, then 
</p>
<dl><dd><span class="mwe-math-element">⠉⠷⠸⠠⠁⠸⠠⠃⠾⠀⠨⠅⠀⠷⠉⠸⠠⠁⠾⠸⠠⠃</span> and <span class="mwe-math-element">⠷⠸⠠⠁⠸⠠⠃⠾⠉⠀⠨⠅⠀⠸⠠⠁⠷⠸⠠⠃⠉⠾⠨⠐</span></dd></dl>
<p>If the scalars have the commutative property, then all four matrices are equal. More generally, all four are equal if <span class="texhtml"><i>c</i></span> belongs to the <a href="/wiki/Center_(algebra)" title="Center (algebra)">center</a> of a <a href="/wiki/Ring_(mathematics)" title="Ring (mathematics)">ring</a> containing the entries of the matrices, because in this case <span class="texhtml"><i>c</i><b>X</b> = <b>X</b><i>c</i></span> for all matrices <span class="texhtml"><b>X</b></span>.
</p><p>These properties result from the <a href="/wiki/Bilinearity" class="mw-redirect" title="Bilinearity">bilinearity</a> of the product of scalars:
</p>
<dl><dd><span class="mwe-math-element">⠉⠷⠐⠨⠠⠎⠩⠅⠻⠁⠰⠊⠅⠐⠃⠰⠅⠚⠐⠾⠀⠨⠅⠀⠐⠨⠠⠎⠩⠅⠻⠷⠉⠁⠰⠊⠅⠐⠾⠃⠰⠅⠚</span></dd>
<dd><span class="mwe-math-element">⠷⠐⠨⠠⠎⠩⠅⠻⠁⠰⠊⠅⠐⠃⠰⠅⠚⠐⠾⠉⠀⠨⠅⠀⠐⠨⠠⠎⠩⠅⠻⠁⠰⠊⠅⠐⠷⠃⠰⠅⠚⠐⠉⠾⠨⠐</span></dd></dl>
<h3><span class="mw-headline">Transpose</span></h3>
<p>If the scalars have the <a href="/wiki/Commutative_property" title="Commutative property">commutative property</a>, the <a href="/wiki/Transpose" title="Transpose">transpose</a> of a product of matrices is the product, in the reverse order, of the transposes of the factors. That is 
</p>
<dl><dd><span class="mwe-math-element">⠷⠸⠠⠁⠸⠠⠃⠾⠘⠠⠨⠠⠞⠐⠀⠨⠅⠀⠸⠠⠃⠘⠠⠨⠠⠞⠐⠸⠠⠁⠘⠠⠨⠠⠞</span></dd></dl>
<p>where <sup>T</sup> denotes the transpose, that is the interchange of rows and columns.
</p><p>This identity does not hold for noncommutative entries, since the order between the entries of <span class="texhtml"><b>A</b></span> and <span class="texhtml"><b>B</b></span> is reversed, when one expands the definition of the matrix product.
</p>
<h3><span class="mw-headline">Complex conjugate</span></h3>
<p>If <span class="texhtml"><b>A</b></span> and <span class="texhtml"><b>B</b></span> have <a href="/wiki/Complex_number" title="Complex number">complex</a> entries, then
</p>
<dl><dd><span class="mwe-math-element">⠷⠸⠠⠁⠸⠠⠃⠾⠘⠈⠼⠐⠀⠨⠅⠀⠸⠠⠁⠘⠈⠼⠐⠸⠠⠃⠘⠈⠼</span></dd></dl>
<p>where <span class="texhtml"><sup>*</sup></span> denotes the entry-wise <a href="/wiki/Complex_conjugate" title="Complex conjugate">complex conjugate</a> of a matrix.
</p><p>This results from applying to the definition of matrix product the fact that the conjugate of a sum is the sum of the conjugates of the summands and the conjugate of a product is the product of the conjugates of the factors.
</p><p>Transposition acts on the indices of the entries, while conjugation acts independently on the entries themselves. It results that, if <span class="texhtml"><b>A</b></span> and <span class="texhtml"><b>B</b></span> have complex entries, one has
</p>
<dl><dd><span class="mwe-math-element">⠷⠸⠠⠁⠸⠠⠃⠾⠘⠸⠻⠐⠀⠨⠅⠀⠸⠠⠃⠘⠸⠻⠐⠸⠠⠁⠘⠸⠻⠐⠠</span></dd></dl>
<p>where <span class="texhtml"><sup>†</sup></span> denotes the <a href="/wiki/Conjugate_transpose" title="Conjugate transpose">conjugate transpose</a> (conjugate of the transpose, or equivalently transpose of the conjugate).
</p>
<h3><span class="mw-headline">Associativity</span></h3>
<p>Given three matrices <span class="texhtml"><b>A</b>, <b>B</b></span> and <span class="texhtml"><b>C</b></span>, the products <span class="texhtml">(<b>AB</b>)<b>C</b></span> and <span class="texhtml"><b>A</b>(<b>BC</b>)</span> are defined if and only if the number of columns of <span class="texhtml"><b>A</b></span> equals the number of rows of <span class="texhtml"><b>B</b></span>  and the number of columns of <span class="texhtml"><b>B</b></span> equals the number of rows of <span class="texhtml"><b>C</b></span> (in particular, if one of the products is defined, the other is also defined). In this case, one has the <a href="/wiki/Associative_property" title="Associative property">associative property</a>
</p>
<dl><dd><span class="mwe-math-element">⠷⠸⠠⠁⠸⠠⠃⠾⠸⠠⠉⠀⠨⠅⠀⠸⠠⠁⠷⠸⠠⠃⠸⠠⠉⠾⠨⠐</span></dd></dl>
<p>As for any associative operation, this allows omitting parentheses, and writing the above products as <span class="mwe-math-element">⠸⠠⠁⠸⠠⠃⠸⠠⠉⠨⠐</span>
</p><p>This extends naturally to the product of any number of matrices provided that the dimensions match. That is, if <span class="texhtml"><b>A</b><sub>1</sub>, <b>A</b><sub>2</sub>, ..., <b>A</b><sub><i>n</i></sub></span> are matrices such that the number of columns of <span class="texhtml"><b>A</b><sub><i>i</i></sub></span> equals the number of rows of <span class="texhtml"><b>A</b><sub><i>i</i> + 1</sub></span> for <span class="texhtml"><i>i</i> = 1, ..., <i>n</i> – 1</span>, then the product 
</p>
<dl><dd><span class="mwe-math-element">⠐⠄⡳⠭⠆⠆⠴⠋⠄⠩⠊⠀⠨⠅⠀⠼⠂⠣⠝⠻⠸⠠⠁⠰⠊⠐⠀⠨⠅⠀⠸⠠⠁⠂⠸⠠⠁⠆⠀⠄⠄⠄⠀⠸⠠⠁⠰⠝⠐</span></dd></dl>
<p>is defined and does not depend on the <a href="/wiki/Order_of_operations" title="Order of operations">order of the multiplications</a>, if the order of the matrices is kept fixed.
</p><p>These properties may be proved by straightforward but complicated <a href="/wiki/Summation" title="Summation">summation</a> manipulations. This result also follows from the fact that matrices represent <a href="/wiki/Linear_map" title="Linear map">linear maps</a>. Therefore, the associative property of matrices is simply a specific case of the associative property of <a href="/wiki/Function_composition" title="Function composition">function composition</a>.
</p>
<h4><span class="mw-headline">Complexity is not associative</span></h4>
<p>Although the result of a sequence of matrix products does not depend on the <a href="/wiki/Order_of_operation" class="mw-redirect" title="Order of operation">order of operation</a> (provided that the order of the matrices is not changed), the <a href="/wiki/Computational_complexity" title="Computational complexity">computational complexity</a> may depend dramatically on this order.
</p><p>For example, if <span class="texhtml"><b>A</b>, <b>B</b></span> and <span class="texhtml"><b>C</b></span> are matrices of respective sizes <span class="texhtml">10×30, 30×5, 5×60</span>, computing <span class="texhtml">(<b>AB</b>)<b>C</b></span> needs <span class="texhtml">10×30×5 + 10×5×60 = 4,500</span> multiplications, while computing <span class="texhtml"><b>A</b>(<b>BC</b>)</span> needs <span class="texhtml">30×5×60 + 10×30×60 = 27,000</span> multiplications.
</p><p>Algorithms have been designed for choosing the best order of products, see <a href="/wiki/Matrix_chain_multiplication" title="Matrix chain multiplication">Matrix chain multiplication</a>. When the number <span class="texhtml mvar" style="font-style:italic;">n</span> of matrices increases, it has been shown that the choice of the best order has a complexity of <span class="mwe-math-element">⠠⠕⠷⠝⠇⠕⠛⠀⠝⠾⠨⠐</span>
</p>
<h4><span class="mw-headline">Application to similarity</span></h4>
<p>Any <a href="/wiki/Invertible_matrix" title="Invertible matrix">invertible matrix</a> <span class="mwe-math-element">⠸⠠⠏</span> defines a <a href="/wiki/Similar_matrix" class="mw-redirect" title="Similar matrix">similarity transformation</a> (on square matrices of the same size as <span class="mwe-math-element">⠸⠠⠏</span>)
</p>
<dl><dd><span class="mwe-math-element">⠠⠎⠰⠸⠠⠏⠐⠷⠸⠠⠁⠾⠀⠨⠅⠀⠸⠠⠏⠘⠤⠼⠂⠐⠸⠠⠁⠸⠠⠏⠨⠐</span></dd></dl>
<p>Similarity transformations map product to products, that is 
</p>
<dl><dd><span class="mwe-math-element">⠠⠎⠰⠸⠠⠏⠐⠷⠸⠠⠁⠸⠠⠃⠾⠀⠨⠅⠀⠠⠎⠰⠸⠠⠏⠐⠷⠸⠠⠁⠾⠠⠎⠰⠸⠠⠏⠐⠷⠸⠠⠃⠾⠨⠐</span></dd></dl>
<p>In fact, one has 
</p>
<dl><dd><span class="mwe-math-element">⠸⠠⠏⠘⠤⠼⠂⠐⠷⠸⠠⠁⠸⠠⠃⠾⠸⠠⠏⠀⠨⠅⠀⠸⠠⠏⠘⠤⠼⠂⠐⠸⠠⠁⠷⠸⠠⠏⠸⠠⠏⠘⠤⠼⠂⠐⠾⠸⠠⠃⠸⠠⠏⠀⠨⠅⠀⠷⠸⠠⠏⠘⠤⠼⠂⠐⠸⠠⠁⠸⠠⠏⠾⠷⠸⠠⠏⠘⠤⠼⠂⠐⠸⠠⠃⠸⠠⠏⠾⠨⠐</span></dd></dl>
<h2><span class="mw-headline">Square matrices</span></h2>
<p>Let us denote <span class="mwe-math-element">⠈⠠⠍⠰⠝⠐⠷⠠⠗⠾</span> the set of <span class="texhtml"><i>n</i>×<i>n</i></span> <a href="/wiki/Square_matrices" class="mw-redirect" title="Square matrices">square matrices</a> with entries in a <a href="/wiki/Ring_(mathematics)" title="Ring (mathematics)">ring</a> <span class="texhtml mvar" style="font-style:italic;">R</span>, which, in practice, is often a <a href="/wiki/Field_(mathematics)" title="Field (mathematics)">field</a>.
</p><p>In <span class="mwe-math-element">⠈⠠⠍⠰⠝⠐⠷⠠⠗⠾</span>, the product is defined for every pair of matrices. This makes <span class="mwe-math-element">⠈⠠⠍⠰⠝⠐⠷⠠⠗⠾</span> a <a href="/wiki/Ring_(mathematics)" title="Ring (mathematics)">ring</a>, which has the <a href="/wiki/Identity_matrix" title="Identity matrix">identity matrix</a> <span class="texhtml"><b>I</b></span> as <a href="/wiki/Identity_element" title="Identity element">identity element</a> (the matrix whose diagonal entries are equal to 1 and all other entries are 0). This ring is also an <a href="/wiki/Associative_algebra" title="Associative algebra">associative <span class="texhtml mvar" style="font-style:italic;">R</span>-algebra</a>.
</p><p>If <span class="texhtml"><i>n</i> &gt; 1</span>, many matrices do not have a <a href="/wiki/Multiplicative_inverse" title="Multiplicative inverse">multiplicative inverse</a>. For example, a matrix such that all entries of a row (or a column) are 0 does not have an inverse. If it exists, the inverse of a matrix <span class="texhtml"><b>A</b></span> is denoted <span class="texhtml"><b>A</b><sup>−1</sup></span>, and, thus verifies
</p>
<dl><dd><span class="mwe-math-element">⠸⠠⠁⠸⠠⠁⠘⠤⠼⠂⠐⠀⠨⠅⠀⠸⠠⠁⠘⠤⠼⠂⠐⠸⠠⠁⠀⠨⠅⠀⠸⠠⠊⠨⠐</span></dd></dl>
<p>A matrix that has an inverse is an <a href="/wiki/Invertible_matrix" title="Invertible matrix">invertible matrix</a>. Otherwise, it is a <a href="/wiki/Singular_matrix" class="mw-redirect" title="Singular matrix">singular matrix</a>.
</p><p>A product of matrices is invertible if and only if each factor is invertible. In this case, one has
</p>
<dl><dd><span class="mwe-math-element">⠷⠸⠠⠁⠸⠠⠃⠾⠘⠤⠼⠂⠐⠀⠨⠅⠀⠸⠠⠃⠘⠤⠼⠂⠐⠸⠠⠁⠘⠤⠼⠂⠐⠨⠐</span></dd></dl>
<p>When <span class="texhtml mvar" style="font-style:italic;">R</span> is <a href="/wiki/Commutative_ring" title="Commutative ring">commutative</a>, and, in particular, when it is a field, the <a href="/wiki/Determinant" title="Determinant">determinant</a> of a product is the product of the determinants. As determinants are scalars, and scalars commute, one has thus 
</p>
<dl><dd><span class="mwe-math-element">⠙⠑⠞⠀⠷⠸⠠⠁⠸⠠⠃⠾⠀⠨⠅⠀⠙⠑⠞⠀⠷⠸⠠⠃⠸⠠⠁⠾⠀⠨⠅⠀⠙⠑⠞⠀⠷⠸⠠⠁⠾⠙⠑⠞⠀⠷⠸⠠⠃⠾⠨⠐</span></dd></dl>
<p>The other matrix <a href="/wiki/Invariant_(mathematics)" title="Invariant (mathematics)">invariants</a> do not behave as well with products. Nevertheless, if <span class="texhtml mvar" style="font-style:italic;">R</span> is commutative, <span class="mwe-math-element">⠸⠠⠁⠸⠠⠃</span> and <span class="mwe-math-element">⠸⠠⠃⠸⠠⠁</span> have the same <a href="/wiki/Trace_(linear_algebra)" title="Trace (linear algebra)">trace</a>, the same <a href="/wiki/Characteristic_polynomial" title="Characteristic polynomial">characteristic polynomial</a>, and the same <a href="/wiki/Eigenvalues" class="mw-redirect" title="Eigenvalues">eigenvalues</a> with the same multiplicities.
However, the <a href="/wiki/Eigenvector" class="mw-redirect" title="Eigenvector">eigenvectors</a> are generally different if <span class="mwe-math-element">⠸⠠⠁⠸⠠⠃⠀⠌⠨⠅⠀⠸⠠⠃⠸⠠⠁⠨⠐</span>
</p>
<h3><span class="mw-headline">Powers of a matrix</span></h3>
<p>One may raise a square matrix to any <a href="/wiki/Exponentiation" title="Exponentiation">nonnegative integer power</a> multiplying it by itself repeatedly in the same way as for ordinary numbers. That is,
</p>
<dl><dd><span class="mwe-math-element">⠸⠠⠁⠘⠴⠐⠀⠨⠅⠀⠸⠠⠊⠠</span></dd>
<dd><span class="mwe-math-element">⠸⠠⠁⠘⠂⠐⠀⠨⠅⠀⠸⠠⠁⠠</span></dd>
<dd><span class="mwe-math-element">⠸⠠⠁⠘⠅⠐⠀⠨⠅⠀⠐⠐⠸⠠⠁⠸⠠⠁⠀⠄⠄⠄⠀⠸⠠⠁⠩⠄⡳⠭⠆⠒⠙⠋⠄⠻⠩⠅⠀⠞⠊⠍⠑⠎⠻⠨⠐</span></dd></dl>
<p>Computing the <span class="texhtml mvar" style="font-style:italic;">k</span>th power of a matrix needs <span class="texhtml"><i>k</i> – 1</span> times the time of a single matrix multiplication, if it is done with the trivial algorithm (repeated multiplication). As this may be very time consuming, one generally prefers using <a href="/wiki/Exponentiation_by_squaring" title="Exponentiation by squaring">exponentiation by squaring</a>, which requires less than <span class="texhtml">2 log<sub>2</sub> <i>k</i></span> matrix multiplications, and is therefore much more efficient.
</p><p>An easy case for exponentiation is that of a <a href="/wiki/Diagonal_matrix" title="Diagonal matrix">diagonal matrix</a>. Since the product of diagonal matrices amounts to simply multiplying corresponding diagonal elements together, the <span class="texhtml"><i>k</i></span>th power of a diagonal matrix is obtained by raising the entries to the power <span class="texhtml"><i>k</i></span>:
</p>
<dl><dd><span class="mwe-math-element">⠠⠷⠁⠂⠂⠀⠴⠀⠄⠄⠄⠀⠴⠠⠾⠀⠠⠷⠴⠀⠁⠆⠆⠀⠄⠄⠄⠀⠴⠠⠾⠀⠠⠷⠣⠄⠄⠄⠀⠣⠄⠄⠄⠀⠰⠄⠄⠄⠀⠣⠄⠄⠄⠠⠾⠀⠠⠷⠴⠀⠴⠀⠄⠄⠄⠀⠁⠰⠝⠝⠐⠠⠾⠘⠅⠐⠀⠨⠅⠀⠠⠷⠁⠂⠂⠘⠅⠐⠀⠴⠀⠄⠄⠄⠀⠴⠠⠾⠀⠠⠷⠴⠀⠁⠆⠆⠘⠅⠐⠀⠄⠄⠄⠀⠴⠠⠾⠀⠠⠷⠣⠄⠄⠄⠀⠣⠄⠄⠄⠀⠰⠄⠄⠄⠀⠣⠄⠄⠄⠠⠾⠀⠠⠷⠴⠀⠴⠀⠄⠄⠄⠀⠁⠰⠝⠝⠘⠅⠐⠠⠾⠨⠐</span></dd></dl>
<h2><span class="mw-headline">Abstract algebra</span></h2>
<p>The definition of matrix product requires that the entries belong to a semiring, and does not require multiplication of elements of the semiring to be <a href="/wiki/Commutative_property" title="Commutative property">commutative</a>. In many applications, the matrix elements belong to a field, although the <a href="/wiki/Tropical_semiring" title="Tropical semiring">tropical semiring</a> is also a common choice for graph <a href="/wiki/Shortest_path" class="mw-redirect" title="Shortest path">shortest path</a> problems.<sup class="reference"><a href="#cite_note-10">[10]</a></sup> Even in the case of matrices over fields, the product is not commutative in general, although it is <a href="/wiki/Associative_property" title="Associative property">associative</a> and is <a href="/wiki/Distributive_property" title="Distributive property">distributive</a> over <a href="/wiki/Matrix_addition" title="Matrix addition">matrix addition</a>. The <a href="/wiki/Identity_matrices" class="mw-redirect" title="Identity matrices">identity matrices</a> (which are the <a href="/wiki/Square_matrices" class="mw-redirect" title="Square matrices">square matrices</a> whose entries are zero outside of the main diagonal and 1 on the main diagonal) are <a href="/wiki/Identity_element" title="Identity element">identity elements</a> of the matrix product. It follows that the <span class="texhtml"><i>n</i> × <i>n</i></span> matrices over a <a href="/wiki/Ring_(mathematics)" title="Ring (mathematics)">ring</a> form a ring, which is noncommutative except if <span class="texhtml"><i>n</i> = 1</span> and the ground ring is commutative.
</p><p>A square matrix may have a <a href="/wiki/Multiplicative_inverse" title="Multiplicative inverse">multiplicative inverse</a>, called an <a href="/wiki/Inverse_matrix" class="mw-redirect" title="Inverse matrix">inverse matrix</a>. In the common case where the entries belong to a <a href="/wiki/Commutative_ring" title="Commutative ring">commutative ring</a> <span class="texhtml mvar" style="font-style:italic;">r</span>, a matrix has an inverse if and only if its <a href="/wiki/Determinant" title="Determinant">determinant</a> has a multiplicative inverse in <span class="texhtml mvar" style="font-style:italic;">r</span>. The determinant of a product of square matrices is the product of the determinants of the factors. The <span class="texhtml"><i>n</i> × <i>n</i></span> matrices that have an inverse form a <a href="/wiki/Group_(mathematics)" title="Group (mathematics)">group</a> under matrix multiplication, the <a href="/wiki/Subgroup" title="Subgroup">subgroups</a> of which are called <a href="/wiki/Matrix_group" class="mw-redirect" title="Matrix group">matrix groups</a>. Many classical groups (including all <a href="/wiki/Finite_group" title="Finite group">finite groups</a>) are <a href="/wiki/Group_isomorphism" title="Group isomorphism">isomorphic</a> to matrix groups; this is the starting point of the theory of <a href="/wiki/Group_representation" title="Group representation">group representations</a>.
</p>
<h2><span class="mw-headline">Computational complexity</span></h2>
<div role="note" class="hatnote navigation-not-searchable">For implementation techniques (in particular parallel and distributed algorithms), see <a href="/wiki/Matrix_multiplication_algorithm" title="Matrix multiplication algorithm">Matrix multiplication algorithm</a>.</div>
<div class="thumb tright"><div class="thumbinner" style="width:402px;"><a href="/wiki/File:MatrixMultComplexity_svg.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/5b/MatrixMultComplexity_svg.svg/400px-MatrixMultComplexity_svg.svg.png" decoding="async" width="400" height="236" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/5b/MatrixMultComplexity_svg.svg/600px-MatrixMultComplexity_svg.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/5b/MatrixMultComplexity_svg.svg/800px-MatrixMultComplexity_svg.svg.png 2x" data-file-width="2085" data-file-height="1228"></a>  <div class="thumbcaption">The bound on <span class="texhtml">ω</span> over time</div></div></div>
<p>The matrix multiplication <a href="/wiki/Algorithm" title="Algorithm">algorithm</a> that results of the definition requires, in the <a href="/wiki/Worst-case_complexity" title="Worst-case complexity">worst case</a>, <span class="mwe-math-element">⠝⠘⠒</span> multiplications of scalars and <span class="mwe-math-element">⠷⠝⠤⠂⠾⠝⠘⠆</span> additions for computing the product of two square <span class="texhtml"><i>n</i>×<i>n</i></span> matrices. Its <a href="/wiki/Computational_complexity" title="Computational complexity">computational complexity</a> is therefore <span class="mwe-math-element">⠠⠕⠷⠝⠘⠒⠐⠾</span>, in a <a href="/wiki/Model_of_computation" title="Model of computation">model of computation</a> for which the scalar operations require a constant time (in practice, this is the case for <a href="/wiki/Floating_point" class="mw-redirect" title="Floating point">floating point</a> numbers, but not for integers).
</p><p>Rather surprisingly, this complexity is not optimal, as shown in 1969 by <a href="/wiki/Volker_Strassen" title="Volker Strassen">Volker Strassen</a>, who provided an algorithm, now called <a href="/wiki/Strassen%27s_algorithm" class="mw-redirect" title="Strassen's algorithm">Strassen's algorithm</a>, with a complexity of <span class="mwe-math-element">⠠⠕⠷⠝⠘⠇⠕⠛⠘⠰⠆⠀⠼⠶⠐⠾⠄⡳⠭⠆⠆⠲⠦⠄⠠⠕⠷⠝⠘⠆⠨⠦⠴⠶⠐⠾⠨⠐</span> The exponent appearing in the complexity of matrix multiplication has been improved several times, leading to 
<a href="/wiki/Coppersmith%E2%80%93Winograd_algorithm" title="Coppersmith–Winograd algorithm">Coppersmith–Winograd algorithm</a> with a complexity of <span class="texhtml"><i>O</i>(<i>n</i><sup>2.376</sup>)</span> (1990).<sup class="reference"><a href="#cite_note-11">[11]</a></sup> This algorithm has been slightly improved in 2013 by <a href="/wiki/Virginia_Vassilevska_Williams" title="Virginia Vassilevska Williams">Virginia Vassilevska Williams</a> to a complexity of <span class="texhtml"><i>O</i>(<i>n</i><sup>2.3729</sup>)</span> and in 2014 by François Le Gall, for a final (up to date) complexity of <span class="texhtml"><i>O</i>(<i>n</i><sup>2.3728639</sup>)</span>.<sup class="reference"><a href="#cite_note-LeGall2014-12">[12]</a></sup>
</p><p>The <a href="/wiki/Greatest_lower_bound" class="mw-redirect" title="Greatest lower bound">greatest lower bound</a> for the exponent of matrix multiplication algorithm is generally called <span class="mwe-math-element">⠨⠕</span>. One has <span class="mwe-math-element">⠼⠆⠀⠐⠅⠱⠀⠨⠕</span>, because one has to read the <span class="mwe-math-element">⠝⠘⠆</span> elements of a matrix for multiplying it by another matrix. Thus <span class="mwe-math-element">⠼⠆⠀⠐⠅⠱⠀⠨⠕⠀⠐⠅⠀⠼⠆⠨⠒⠶⠒</span>. It is unknown whether <span class="mwe-math-element">⠼⠆⠀⠐⠅⠀⠨⠕</span>. The largest known lower bound for matrix-multiplication complexity is <span class="texhtml">Ω(<i>n</i><sup>2</sup> log(<i>n</i>))</span>, for a restricted kind of <a href="/wiki/Arithmetic_circuit_complexity" title="Arithmetic circuit complexity">arithmetic circuits</a>, and is due to <a href="/wiki/Ran_Raz" title="Ran Raz">Ran Raz</a>.<sup class="reference"><a href="#cite_note-13">[13]</a></sup>
</p>
<h3><span class="mw-headline">Related complexities</span></h3>
<p>The importance of the computational complexity of matrix multiplication relies on the facts that many algorithmic problems may be solved by means of matrix computation, and most problems on matrices have a complexity which is either the same as that of matrix multiplication (up to a multiplicative constant), or may be expressed in term of the complexity of matrix multiplication or its exponent <span class="mwe-math-element">⠨⠕⠨⠐</span>
</p><p>There are several advantages of expressing complexities in terms of the exponent <span class="mwe-math-element">⠨⠕</span> of matrix multiplication. Firstly, if <span class="mwe-math-element">⠨⠕</span> is improved, this will automatically improve the known upper bound of complexity of many algorithms. Secondly, in practical implementations, one never uses the matrix multiplication algorithm that has the best asymptotical complexity, because the constant hidden behind the <a href="/wiki/Big_O_notation" title="Big O notation">big O notation</a> is too large for making the algorithm competitive for sizes of matrices that can be manipulated in a computer. Thus expressing complexities in terms of <span class="mwe-math-element">⠨⠕</span> provide a more realistic complexity, since it remains valid whichever algorithm is chosen for matrix computation.
</p><p>Problems that have the same asymptotic complexity as matrix multiplication include <a href="/wiki/Determinant" title="Determinant">determinant</a>, <a href="/wiki/Matrix_inversion" class="mw-redirect" title="Matrix inversion">matrix inversion</a>, <a href="/wiki/Gaussian_elimination" title="Gaussian elimination">Gaussian elimination</a> (see next section). Problems with complexity that is expressible in terms of <span class="mwe-math-element">⠨⠕</span> include <a href="/wiki/Characteristic_polynomial" title="Characteristic polynomial">characteristic polynomial</a>, <a href="/wiki/Eigenvalues" class="mw-redirect" title="Eigenvalues">eigenvalues</a> (but not <a href="/wiki/Eigenvectors" class="mw-redirect" title="Eigenvectors">eigenvectors</a>), <a href="/wiki/Hermite_normal_form" title="Hermite normal form">Hermite normal form</a>, and <a href="/wiki/Smith_normal_form" title="Smith normal form">Smith normal form</a>.
</p>
<h3><span></span><span class="mw-headline">Matrix inversion, determinant and Gaussian elimination</span></h3>
<p>In his 1969 paper, where he proved the complexity <span class="mwe-math-element">⠠⠕⠷⠝⠘⠆⠨⠦⠴⠶⠐⠾</span> for matrix computation, Strassen proved also that <a href="/wiki/Matrix_inversion" class="mw-redirect" title="Matrix inversion">Matrix inversion</a>, <a href="/wiki/Determinant" title="Determinant">determinant</a> and <a href="/wiki/Gaussian_elimination" title="Gaussian elimination">Gaussian elimination</a> have, up to a multiplicative constant, the same <a href="/wiki/Computational_complexity" title="Computational complexity">computational complexity</a> as matrix multiplication. The proof does not make any assumptions on matrix multiplication that is used, except that its complexity is <span class="mwe-math-element">⠠⠕⠷⠝⠘⠨⠕⠐⠾</span> for some <span class="mwe-math-element">⠨⠕⠀⠨⠂⠱⠀⠼⠆</span>
</p><p>The starting point of Strassen's proof is using <a href="/wiki/Block_matrix" title="Block matrix">block matrix</a> multiplication. Specifically, a matrix of even dimension <span class="texhtml">2<i>n</i>×2<i>n</i></span> may be partitioned in four <span class="texhtml"><i>n</i>×<i>n</i></span> blocks
</p>
<dl><dd><span class="mwe-math-element">⠈⠠⠷⠠⠁⠀⠠⠃⠈⠠⠾⠀⠈⠠⠷⠠⠉⠀⠠⠙⠈⠠⠾⠨⠐</span></dd></dl>
<p>Under this form, its inverse is 
</p>
<dl><dd><span class="mwe-math-element">⠈⠠⠷⠠⠁⠀⠠⠃⠈⠠⠾⠀⠈⠠⠷⠠⠉⠀⠠⠙⠈⠠⠾⠘⠤⠼⠂⠐⠀⠨⠅⠀⠈⠠⠷⠠⠁⠘⠤⠼⠂⠐⠬⠠⠁⠘⠤⠼⠂⠐⠠⠃⠷⠠⠙⠤⠠⠉⠠⠁⠘⠤⠼⠂⠐⠠⠃⠾⠘⠤⠼⠂⠐⠠⠉⠠⠁⠘⠤⠼⠂⠐⠀⠤⠠⠁⠘⠤⠼⠂⠐⠠⠃⠷⠠⠙⠤⠠⠉⠠⠁⠘⠤⠼⠂⠐⠠⠃⠾⠘⠤⠼⠂⠐⠈⠠⠾⠀⠈⠠⠷⠤⠷⠠⠙⠤⠠⠉⠠⠁⠘⠤⠼⠂⠐⠠⠃⠾⠘⠤⠼⠂⠐⠠⠉⠠⠁⠘⠤⠼⠂⠐⠀⠷⠠⠙⠤⠠⠉⠠⠁⠘⠤⠼⠂⠐⠠⠃⠾⠘⠤⠼⠂⠐⠈⠠⠾⠠</span></dd></dl>
<p>provided that <span class="texhtml mvar" style="font-style:italic;">A</span> and <span class="mwe-math-element">⠠⠙⠤⠠⠉⠠⠁⠘⠤⠼⠂⠐⠠⠃</span> are invertible.
</p><p>Thus, the inverse of a <span class="texhtml">2<i>n</i>×2<i>n</i></span> matrix may be computed with two inversions, six multiplications and four additions or additive inverses of <span class="texhtml"><i>n</i>×<i>n</i></span> matrices. It follows that, denoting respectively by <span class="texhtml"><i>I</i>(<i>n</i>)</span>, <span class="texhtml"><i>M</i>(<i>n</i>)</span> and <span class="texhtml"><i>A</i>(<i>n</i>) = <i>n</i><sup>2</sup></span> the number of operations needed for inverting, multiplying and adding <span class="texhtml"><i>n</i>×<i>n</i></span> matrices, one has 
</p>
<dl><dd><span class="mwe-math-element">⠠⠊⠷⠼⠆⠝⠾⠀⠐⠅⠱⠀⠼⠆⠠⠊⠷⠝⠾⠬⠖⠠⠍⠷⠝⠾⠬⠲⠠⠁⠷⠝⠾⠨⠐</span></dd></dl>
<p>If <span class="mwe-math-element">⠝⠀⠨⠅⠀⠼⠆⠘⠅⠐⠠</span> one may apply this formula recursively:
</p>
<dl><dd><span class="mwe-math-element">⠠⠊⠷⠼⠆⠘⠅⠐⠾⠀⠀⠐⠅⠱⠀⠼⠆⠠⠊⠷⠼⠆⠘⠅⠤⠂⠐⠾⠬⠖⠠⠍⠷⠼⠆⠘⠅⠤⠂⠐⠾⠬⠲⠠⠁⠷⠼⠆⠘⠅⠤⠂⠐⠾⠀⠀⠀⠀⠐⠅⠱⠀⠼⠆⠘⠆⠐⠠⠊⠷⠼⠆⠘⠅⠤⠆⠐⠾⠬⠖⠷⠠⠍⠷⠼⠆⠘⠅⠤⠂⠐⠾⠬⠆⠠⠍⠷⠼⠆⠘⠅⠤⠆⠐⠾⠾⠬⠲⠷⠠⠁⠷⠼⠆⠘⠅⠤⠂⠐⠾⠬⠆⠠⠁⠷⠼⠆⠘⠅⠤⠆⠐⠾⠾⠀⠀⠀⠄⠄⠄</span></dd></dl>
<p>If <span class="mwe-math-element">⠠⠍⠷⠝⠾⠀⠐⠅⠱⠀⠉⠝⠘⠨⠕⠐⠠</span> and <span class="mwe-math-element">⠨⠁⠀⠨⠅⠀⠼⠆⠘⠨⠕⠐⠀⠨⠂⠱⠀⠼⠲⠠</span> one gets eventually 
</p>
<dl><dd><span class="mwe-math-element">⠠⠊⠷⠼⠆⠘⠅⠐⠾⠀⠀⠐⠅⠱⠀⠼⠆⠘⠅⠐⠠⠊⠷⠼⠂⠾⠬⠖⠉⠷⠨⠁⠘⠅⠤⠂⠐⠬⠆⠨⠁⠘⠅⠤⠆⠐⠬⠄⠄⠄⠬⠆⠘⠅⠤⠂⠐⠨⠁⠘⠴⠐⠾⠬⠅⠆⠘⠅⠬⠂⠐⠀⠀⠀⠀⠐⠅⠱⠀⠼⠆⠘⠅⠐⠬⠖⠉⠹⠨⠁⠘⠅⠐⠤⠆⠘⠅⠐⠌⠨⠁⠤⠆⠼⠬⠅⠆⠘⠅⠬⠂⠐⠀⠀⠀⠀⠐⠅⠱⠀⠙⠷⠆⠘⠅⠐⠾⠘⠨⠕⠐⠨⠐</span></dd></dl>
<p>for some constant <span class="texhtml mvar" style="font-style:italic;">d</span>.
</p><p>For matrices whose dimension is not a power of two, the same complexity is reached by increasing the dimension of the matrix to a power of two, by padding the matrix with rows and columns whose entries are 1 on the diagonal and 0 elsewhere.
</p><p>This proves the asserted complexity for matrices such that all submatrices that have to be inverted are indeed invertible. This complexity is thus proved for almost all matrices, as a matrix with randomly chosen entries is invertible with probability one.
</p><p>The same argument applies to <a href="/wiki/LU_decomposition" title="LU decomposition">LU decomposition</a>, as, if the matrix <span class="texhtml mvar" style="font-style:italic;">A</span> is invertible, the equality
</p>
<dl><dd><span class="mwe-math-element">⠈⠠⠷⠠⠁⠀⠠⠃⠈⠠⠾⠀⠈⠠⠷⠠⠉⠀⠠⠙⠈⠠⠾⠀⠨⠅⠀⠈⠠⠷⠠⠊⠀⠴⠈⠠⠾⠀⠈⠠⠷⠠⠉⠠⠁⠘⠤⠼⠂⠐⠀⠠⠊⠈⠠⠾⠈⠠⠷⠠⠁⠀⠠⠃⠈⠠⠾⠀⠈⠠⠷⠴⠀⠠⠙⠤⠠⠉⠠⠁⠘⠤⠼⠂⠐⠠⠃⠈⠠⠾</span></dd></dl>
<p>defines a block LU decomposition that may be applied recursively to <span class="mwe-math-element">⠠⠁</span> and <span class="mwe-math-element">⠠⠙⠤⠠⠉⠠⠁⠘⠤⠼⠂⠐⠠⠃⠠</span> for getting eventually a true LU decomposition of the original matrix.
</p><p>The argument applies also for the determinant, since it results from the block LU decomposition that 
</p>
<dl><dd><span class="mwe-math-element">⠙⠑⠞⠀⠈⠠⠷⠠⠁⠀⠠⠃⠈⠠⠾⠀⠈⠠⠷⠠⠉⠀⠠⠙⠈⠠⠾⠀⠨⠅⠀⠙⠑⠞⠀⠷⠠⠁⠾⠙⠑⠞⠀⠷⠠⠙⠤⠠⠉⠠⠁⠘⠤⠼⠂⠐⠠⠃⠾⠨⠐</span></dd></dl>
<h2><span class="mw-headline">See also</span></h2>
<ul><li><a href="/wiki/Matrix_calculus" title="Matrix calculus">Matrix calculus</a>, for the interaction of matrix multiplication with operations from calculus</li>
<li>Other types of products of matrices:
<ul><li><a href="/wiki/Block_matrix#Block_matrix_multiplication" title="Block matrix">Block matrix multiplication</a></li>
<li><a href="/wiki/Cracovian_product" class="mw-redirect" title="Cracovian product">Cracovian product</a>, defined as <span class="texhtml"><b>A</b> ∧ <b>B</b> = <b>B</b><sup>T</sup><b>A</b></span></li>
<li><a href="/wiki/Frobenius_inner_product" title="Frobenius inner product">Frobenius inner product</a>, the <a href="/wiki/Dot_product" title="Dot product">dot product</a> of matrices considered as vectors, or, equivalently the sum of the entries of the Hadamard product</li>
<li><a href="/wiki/Hadamard_product_(matrices)" title="Hadamard product (matrices)">Hadamard product</a> of two matrices of the same size, resulting in a matrix of the same size, which is the product entry-by-entry</li>
<li><a href="/wiki/Kronecker_product" title="Kronecker product">Kronecker product</a> or <a href="/wiki/Tensor_product" title="Tensor product">tensor product</a>, the generalization to any size of the preceding</li>
<li><a href="/wiki/Outer_product" title="Outer product">Outer product</a>, also called <a href="/wiki/Dyadic_product" class="mw-redirect" title="Dyadic product">dyadic product</a> or <a href="/wiki/Tensor_product" title="Tensor product">tensor product</a> of two column matrices, which is <span class="mwe-math-element">⠸⠁⠸⠃⠘⠠⠨⠠⠞</span></li></ul></li></ul>
<h2><span class="mw-headline">Notes</span></h2>
<div class="reflist columns references-column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;">
<ol class="references">
<li> <span class="reference-text"><cite class="citation cs2"><a href="/wiki/John_J._O%27Connor_(mathematician)" class="mw-redirect" title="John J. O'Connor (mathematician)">O'Connor, John J.</a>; <a href="/wiki/Edmund_F._Robertson" title="Edmund F. Robertson">Robertson, Edmund F.</a>, <a rel="nofollow" class="external text" href="http://www-history.mcs.st-andrews.ac.uk/Biographies/Binet.html">"Jacques Philippe Marie Binet"</a>, <i><a href="/wiki/MacTutor_History_of_Mathematics_archive" title="MacTutor History of Mathematics archive">MacTutor History of Mathematics archive</a></i>, <a href="/wiki/University_of_St_Andrews" title="University of St Andrews">University of St Andrews</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Jacques+Philippe+Marie+Binet&amp;rft.btitle=MacTutor+History+of+Mathematics+archive&amp;rft.pub=University+of+St+Andrews&amp;rft.aulast=O%27Connor&amp;rft.aufirst=John+J.&amp;rft.au=Robertson%2C+Edmund+F.&amp;rft_id=http%3A%2F%2Fwww-history.mcs.st-andrews.ac.uk%2FBiographies%2FBinet.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r951705291">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg");background-repeat:no-repeat;background-size:9px;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg");background-repeat:no-repeat;background-size:9px;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg");background-repeat:no-repeat;background-size:9px;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg");background-repeat:no-repeat;background-size:12px;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style>.</span>
</li>
<li> <span class="reference-text"><cite class="citation book cs1">Lerner, R. G.; Trigg, G. L. (1991). <i>Encyclopaedia of Physics</i> (2nd ed.). VHC publishers. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978-3-527-26954-9" title="Special:BookSources/978-3-527-26954-9">978-3-527-26954-9</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Encyclopaedia+of+Physics&amp;rft.edition=2nd&amp;rft.pub=VHC+publishers&amp;rft.date=1991&amp;rft.isbn=978-3-527-26954-9&amp;rft.aulast=Lerner&amp;rft.aufirst=R.+G.&amp;rft.au=Trigg%2C+G.+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation book cs1">Parker, C. B. (1994). <span class="cs1-lock-registration" title="Free registration required"><a rel="nofollow" class="external text" href="https://archive.org/details/mcgrawhillencycl1993park"><i>McGraw Hill Encyclopaedia of Physics</i></a></span> (2nd ed.). <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978-0-07-051400-3" title="Special:BookSources/978-0-07-051400-3">978-0-07-051400-3</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=McGraw+Hill+Encyclopaedia+of+Physics&amp;rft.edition=2nd&amp;rft.date=1994&amp;rft.isbn=978-0-07-051400-3&amp;rft.aulast=Parker&amp;rft.aufirst=C.+B.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fmcgrawhillencycl1993park&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation book cs1">Lipschutz, S.; Lipson, M. (2009). <i>Linear Algebra</i>. Schaum's Outlines (4th ed.). McGraw Hill (USA). pp.&nbsp;30–31. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978-0-07-154352-1" title="Special:BookSources/978-0-07-154352-1">978-0-07-154352-1</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Linear+Algebra&amp;rft.series=Schaum%27s+Outlines&amp;rft.pages=30-31&amp;rft.edition=4th&amp;rft.pub=McGraw+Hill+%28USA%29&amp;rft.date=2009&amp;rft.isbn=978-0-07-154352-1&amp;rft.aulast=Lipschutz&amp;rft.aufirst=S.&amp;rft.au=Lipson%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation book cs1">Riley, K. F.; Hobson, M. P.; Bence, S. J. (2010). <span class="cs1-lock-registration" title="Free registration required"><a rel="nofollow" class="external text" href="https://archive.org/details/mathematicalmeth00rile"><i>Mathematical methods for physics and engineering</i></a></span>. Cambridge University Press. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978-0-521-86153-3" title="Special:BookSources/978-0-521-86153-3">978-0-521-86153-3</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mathematical+methods+for+physics+and+engineering&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2010&amp;rft.isbn=978-0-521-86153-3&amp;rft.aulast=Riley&amp;rft.aufirst=K.+F.&amp;rft.au=Hobson%2C+M.+P.&amp;rft.au=Bence%2C+S.+J.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fmathematicalmeth00rile&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation book cs1">Adams, R. A. (1995). <i>Calculus, A Complete Course</i> (3rd ed.). Addison Wesley. p.&nbsp;627. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/0_201_82823_5" title="Special:BookSources/0 201 82823 5">0 201 82823 5</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Calculus%2C+A+Complete+Course&amp;rft.pages=627&amp;rft.edition=3rd&amp;rft.pub=Addison+Wesley&amp;rft.date=1995&amp;rft.isbn=0201828235&amp;rft.aulast=Adams&amp;rft.aufirst=R.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation book cs1">Horn, Johnson (2013). <i>Matrix Analysis</i> (2nd ed.). Cambridge University Press. p.&nbsp;6. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978_0_521_54823_6" title="Special:BookSources/978 0 521 54823 6">978 0 521 54823 6</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Matrix+Analysis&amp;rft.pages=6&amp;rft.edition=2nd&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2013&amp;rft.isbn=9780521548236&amp;rft.aulast=Horn&amp;rft.aufirst=Johnson&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation book cs1">Lipcshutz, S.; Lipson, M. (2009). "2". <i>Linear Algebra</i>. Schaum's Outlines (4th ed.). McGraw Hill (USA). <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978-0-07-154352-1" title="Special:BookSources/978-0-07-154352-1">978-0-07-154352-1</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=2&amp;rft.btitle=Linear+Algebra&amp;rft.series=Schaum%27s+Outlines&amp;rft.edition=4th&amp;rft.pub=McGraw+Hill+%28USA%29&amp;rft.date=2009&amp;rft.isbn=978-0-07-154352-1&amp;rft.aulast=Lipcshutz&amp;rft.aufirst=S.&amp;rft.au=Lipson%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation book cs1">Horn, Johnson (2013). "0". <i>Matrix Analysis</i> (2nd ed.). Cambridge University Press. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978_0_521_54823_6" title="Special:BookSources/978 0 521 54823 6">978 0 521 54823 6</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=0&amp;rft.btitle=Matrix+Analysis&amp;rft.edition=2nd&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2013&amp;rft.isbn=9780521548236&amp;rft.aulast=Horn&amp;rft.aufirst=Johnson&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation book cs1"><a href="/wiki/Rajeev_Motwani" title="Rajeev Motwani">Motwani, Rajeev</a>; <a href="/wiki/Prabhakar_Raghavan" title="Prabhakar Raghavan">Raghavan, Prabhakar</a> (1995). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=QKVY4mDivBEC&amp;pg=PA280"><i>Randomized Algorithms</i></a>. Cambridge University Press. p.&nbsp;280. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/9780521474658" title="Special:BookSources/9780521474658">9780521474658</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Randomized+Algorithms&amp;rft.pages=280&amp;rft.pub=Cambridge+University+Press&amp;rft.date=1995&amp;rft.isbn=9780521474658&amp;rft.aulast=Motwani&amp;rft.aufirst=Rajeev&amp;rft.au=Raghavan%2C+Prabhakar&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DQKVY4mDivBEC%26pg%3DPA280&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation web cs1"><a href="/wiki/Virginia_Vassilevska_Williams" title="Virginia Vassilevska Williams">Williams, Virginia Vassilevska</a>. <a rel="nofollow" class="external text" href="http://www.cs.stanford.edu/~virgi/matrixmult-f.pdf">"Multiplying matrices faster than Coppersmith-Winograd"</a> <span class="cs1-format">(PDF)</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Multiplying+matrices+faster+than+Coppersmith-Winograd&amp;rft.aulast=Williams&amp;rft.aufirst=Virginia+Vassilevska&amp;rft_id=http%3A%2F%2Fwww.cs.stanford.edu%2F~virgi%2Fmatrixmult-f.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation cs2">Le Gall, François (2014), "Powers of tensors and fast matrix multiplication", <i>Proceedings of the 39th International Symposium on Symbolic and Algebraic Computation (ISSAC 2014)</i>, <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1401.7714">1401.7714</a></span>, <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2014arXiv1401.7714L">2014arXiv1401.7714L</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Powers+of+tensors+and+fast+matrix+multiplication&amp;rft.btitle=Proceedings+of+the+39th+International+Symposium+on+Symbolic+and+Algebraic+Computation+%28ISSAC+2014%29&amp;rft.date=2014&amp;rft_id=info%3Aarxiv%2F1401.7714&amp;rft_id=info%3Abibcode%2F2014arXiv1401.7714L&amp;rft.aulast=Le+Gall&amp;rft.aufirst=Fran%C3%A7ois&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
<li> <span class="reference-text"><cite class="citation journal cs1">Raz, Ran (January 2003). "On the Complexity of Matrix Product". <i>SIAM Journal on Computing</i>. <b>32</b> (5): 1356–1369. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1137%2Fs0097539702402147">10.1137/s0097539702402147</a>. <a href="/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0097-5397">0097-5397</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=SIAM+Journal+on+Computing&amp;rft.atitle=On+the+Complexity+of+Matrix+Product&amp;rft.volume=32&amp;rft.issue=5&amp;rft.pages=1356-1369&amp;rft.date=2003-01&amp;rft_id=info%3Adoi%2F10.1137%2Fs0097539702402147&amp;rft.issn=0097-5397&amp;rft.aulast=Raz&amp;rft.aufirst=Ran&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></span>
</li>
</ol></div>
<h2><span class="mw-headline">References</span></h2>
<table role="presentation" class="mbox-small plainlinks sistersitebox" style="background-color:#f9f9f9;border:1px solid #aaa;color:#000">
<tbody><tr>
<td class="mbox-image"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png" decoding="async" width="30" height="40" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/45px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/59px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376"></td>
<td class="mbox-text plainlist">Wikimedia Commons has media related to <i><b><a href="https://commons.wikimedia.org/wiki/Category:Matrix_multiplication" class="extiw" title="commons:Category:Matrix multiplication"><span style="">matrix multiplication</span></a></b></i>.</td></tr>
</tbody></table>
<table role="presentation" class="mbox-small plainlinks sistersitebox" style="background-color:#f9f9f9;border:1px solid #aaa;color:#000">
<tbody><tr>
<td class="mbox-image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/40px-Wikibooks-logo-en-noslogan.svg.png" decoding="async" width="40" height="40" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/60px-Wikibooks-logo-en-noslogan.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/80px-Wikibooks-logo-en-noslogan.svg.png 2x" data-file-width="400" data-file-height="400"></td>
<td class="mbox-text plainlist">The Wikibook <i><a href="https://en.wikibooks.org/wiki/Linear_Algebra" class="extiw" title="wikibooks:Linear Algebra">Linear Algebra</a></i> has a page on the topic of: <i><b><a href="https://en.wikibooks.org/wiki/Linear_Algebra/Matrix_Multiplication" class="extiw" title="wikibooks:Linear Algebra/Matrix Multiplication">Matrix multiplication</a></b></i></td></tr>
</tbody></table>
<table role="presentation" class="mbox-small plainlinks sistersitebox" style="background-color:#f9f9f9;border:1px solid #aaa;color:#000">
<tbody><tr>
<td class="mbox-image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/40px-Wikibooks-logo-en-noslogan.svg.png" decoding="async" width="40" height="40" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/60px-Wikibooks-logo-en-noslogan.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/80px-Wikibooks-logo-en-noslogan.svg.png 2x" data-file-width="400" data-file-height="400"></td>
<td class="mbox-text plainlist">The Wikibook <i><a href="https://en.wikibooks.org/wiki/Applicable_Mathematics" class="extiw" title="wikibooks:Applicable Mathematics">Applicable Mathematics</a></i> has a page on the topic of: <i><b><a href="https://en.wikibooks.org/wiki/Applicable_Mathematics/Matrices#Multiplying_Matrices" class="extiw" title="wikibooks:Applicable Mathematics/Matrices">Multiplying Matrices</a></b></i></td></tr>
</tbody></table>
<style data-mw-deduplicate="TemplateStyles:r886047268">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class="refbegin reflist" style="">
<ul><li>Henry Cohn, <a href="/wiki/Robert_Kleinberg" title="Robert Kleinberg">Robert Kleinberg</a>, <a href="/wiki/Bal%C3%A1zs_Szegedy" title="Balázs Szegedy">Balázs Szegedy</a>, and Chris Umans. Group-theoretic Algorithms for Matrix Multiplication. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<a rel="nofollow" class="external text" href="https://arxiv.org/abs/math.GR/0511460">math.GR/0511460</a>. <i>Proceedings of the 46th Annual Symposium on Foundations of Computer Science</i>, 23–25 October 2005, Pittsburgh, PA, IEEE Computer Society, pp.&nbsp;379–388.</li>
<li>Henry Cohn, Chris Umans. A Group-theoretic Approach to Fast Matrix Multiplication. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<a rel="nofollow" class="external text" href="https://arxiv.org/abs/math.GR/0307321">math.GR/0307321</a>. <i>Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science</i>, 11–14 October 2003, Cambridge, MA, IEEE Computer Society, pp.&nbsp;438–449.</li>
<li><cite class="citation journal cs1">Coppersmith, D.; Winograd, S. (1990). "Matrix multiplication via arithmetic progressions". <i>J. Symbolic Comput</i>. <b>9</b> (3): 251–280. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fs0747-7171%2808%2980013-2">10.1016/s0747-7171(08)80013-2</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J.+Symbolic+Comput.&amp;rft.atitle=Matrix+multiplication+via+arithmetic+progressions&amp;rft.volume=9&amp;rft.issue=3&amp;rft.pages=251-280&amp;rft.date=1990&amp;rft_id=info%3Adoi%2F10.1016%2Fs0747-7171%2808%2980013-2&amp;rft.aulast=Coppersmith&amp;rft.aufirst=D.&amp;rft.au=Winograd%2C+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></li>
<li><cite class="citation cs2">Horn, Roger A.; Johnson, Charles R. (1991), <i>Topics in Matrix Analysis</i>, <a href="/wiki/Cambridge_University_Press" title="Cambridge University Press">Cambridge University Press</a>, <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978-0-521-46713-1" title="Special:BookSources/978-0-521-46713-1">978-0-521-46713-1</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Topics+in+Matrix+Analysis&amp;rft.pub=Cambridge+University+Press&amp;rft.date=1991&amp;rft.isbn=978-0-521-46713-1&amp;rft.aulast=Horn&amp;rft.aufirst=Roger+A.&amp;rft.au=Johnson%2C+Charles+R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></li>
<li><a href="/wiki/Donald_Knuth" title="Donald Knuth">Knuth, D.E.</a>, <i><a href="/wiki/The_Art_of_Computer_Programming" title="The Art of Computer Programming">The Art of Computer Programming</a> Volume 2: Seminumerical Algorithms</i>. Addison-Wesley Professional; 3 edition (November 14, 1997). <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"><a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978-0-201-89684-8" title="Special:BookSources/978-0-201-89684-8">978-0-201-89684-8</a>. pp.&nbsp;501.</li>
<li><cite class="citation cs2">Press, William H.; Flannery, Brian P.; <a href="/wiki/Saul_Teukolsky" title="Saul Teukolsky">Teukolsky, Saul A.</a>; Vetterling, William T. (2007), <a href="/wiki/Numerical_Recipes" title="Numerical Recipes"><i>Numerical Recipes: The Art of Scientific Computing</i></a> (3rd ed.), <a href="/wiki/Cambridge_University_Press" title="Cambridge University Press">Cambridge University Press</a>, <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978-0-521-88068-8" title="Special:BookSources/978-0-521-88068-8">978-0-521-88068-8</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Numerical+Recipes%3A+The+Art+of+Scientific+Computing&amp;rft.edition=3rd&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2007&amp;rft.isbn=978-0-521-88068-8&amp;rft.aulast=Press&amp;rft.aufirst=William+H.&amp;rft.au=Flannery%2C+Brian+P.&amp;rft.au=Teukolsky%2C+Saul+A.&amp;rft.au=Vetterling%2C+William+T.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291">.</li>
<li><a href="/wiki/Ran_Raz" title="Ran Raz">Ran Raz</a>. On the complexity of matrix product. In Proceedings of the thirty-fourth annual ACM symposium on Theory of computing. ACM Press, 2002. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F509907.509932">10.1145/509907.509932</a>.</li>
<li>Robinson, Sara, <i>Toward an Optimal Algorithm for Matrix Multiplication,</i> SIAM News 38(9), November 2005. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20100331095603/http://www.siam.org/pdf/news/174.pdf">PDF</a></li>
<li>Strassen, Volker, <i>Gaussian Elimination is not Optimal</i>, Numer. Math. 13, p.&nbsp;354-356, 1969.</li>
<li><cite class="citation cs2">Styan, George P. H. (1973), <a rel="nofollow" class="external text" href="http://dml.cz/bitstream/handle/10338.dmlcz/102190/CzechMathJ_37-1987-4_14.pdf">"Hadamard Products and Multivariate Statistical Analysis"</a> <span class="cs1-format">(PDF)</span>, <i>Linear Algebra and its Applications</i>, <b>6</b>: 217–240, <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2F0024-3795%2873%2990023-2">10.1016/0024-3795(73)90023-2</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Linear+Algebra+and+its+Applications&amp;rft.atitle=Hadamard+Products+and+Multivariate+Statistical+Analysis&amp;rft.volume=6&amp;rft.pages=217-240&amp;rft.date=1973&amp;rft_id=info%3Adoi%2F10.1016%2F0024-3795%2873%2990023-2&amp;rft.aulast=Styan&amp;rft.aufirst=George+P.+H.&amp;rft_id=http%3A%2F%2Fdml.cz%2Fbitstream%2Fhandle%2F10338.dmlcz%2F102190%2FCzechMathJ_37-1987-4_14.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></li>
<li><cite class="citation book cs1">Williams, Virginia Vassilevska (2012-05-19). <a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=2213977.2214056">"Multiplying matrices faster than coppersmith-winograd"</a>. <i>Proceedings of the 44th symposium on Theory of Computing - STOC '12</i>. ACM. pp.&nbsp;887–898. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&nbsp;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.297.2680">10.1.1.297.2680</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F2213977.2214056">10.1145/2213977.2214056</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/9781450312455" title="Special:BookSources/9781450312455">9781450312455</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Multiplying+matrices+faster+than+coppersmith-winograd&amp;rft.btitle=Proceedings+of+the+44th+symposium+on+Theory+of+Computing+-+STOC+%2712&amp;rft.pages=887-898&amp;rft.pub=ACM&amp;rft.date=2012-05-19&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.297.2680&amp;rft_id=info%3Adoi%2F10.1145%2F2213977.2214056&amp;rft.isbn=9781450312455&amp;rft.aulast=Williams&amp;rft.aufirst=Virginia+Vassilevska&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D2213977.2214056&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMatrix+multiplication" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"></li></ul>
</div>
<div role="navigation" class="navbox" aria-labelledby="Algebra" style="padding:3px"><table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Algebra" title="Template:Algebra"><abbr title="View this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Algebra" title="Template talk:Algebra"><abbr title="Discuss this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Algebra&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">e</abbr></a></li></ul></div><div style="font-size:114%;margin:0 4em"><a href="/wiki/Algebra" title="Algebra">Algebra</a></div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%">Areas</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Abstract_algebra" title="Abstract algebra">Abstract algebra</a></li>
<li><a href="/wiki/Category_theory" title="Category theory">Category theory</a></li>
<li><a href="/wiki/Elementary_algebra" title="Elementary algebra">Elementary algebra</a></li>
<li><a href="/wiki/K-theory" title="K-theory">K-theory</a></li>
<li><a href="/wiki/Commutative_algebra" title="Commutative algebra">Commutative algebra</a></li>
<li><a href="/wiki/Noncommutative_algebra" class="mw-redirect" title="Noncommutative algebra">Noncommutative algebra</a></li>
<li><a href="/wiki/Order_theory" title="Order theory">Order theory</a></li>
<li><a href="/wiki/Universal_algebra" title="Universal algebra">Universal algebra</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Algebraic_structure" title="Algebraic structure">Algebraic structures</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Group_(mathematics)" title="Group (mathematics)">Group</a>&nbsp;(<a href="/wiki/Group_theory" title="Group theory">theory</a>)</li>
<li><a href="/wiki/Ring_(mathematics)" title="Ring (mathematics)">Ring</a>&nbsp;(<a href="/wiki/Ring_theory" title="Ring theory">theory</a>)</li>
<li><a href="/wiki/Module_(mathematics)" title="Module (mathematics)">Module</a>&nbsp;(<a href="/wiki/Commutative_algebra" title="Commutative algebra">theory</a>)</li>
<li><a href="/wiki/Field_(mathematics)" title="Field (mathematics)">Field</a></li>
<li><a href="/wiki/Polynomial_ring" title="Polynomial ring">Polynomial ring</a>&nbsp;(<a href="/wiki/Polynomial" title="Polynomial">Polynomial</a>)</li>
<li><a href="/wiki/Composition_algebra" title="Composition algebra">Composition algebra</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Linear_algebra" title="Linear algebra">Linear algebra</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Matrix_(mathematics)" title="Matrix (mathematics)">Matrix&nbsp;(theory)</a></li>
<li><a href="/wiki/Vector_space" title="Vector space">Vector space</a>&nbsp;(<a href="/wiki/Coordinate_vector" title="Coordinate vector">Vector</a>)</li>
<li><a href="/wiki/Module_(mathematics)" title="Module (mathematics)">Module</a></li>
<li><a href="/wiki/Inner_product_space" title="Inner product space">Inner product space</a> (<a href="/wiki/Dot_product" title="Dot product">dot product</a>)</li>
<li><a href="/wiki/Hilbert_space" title="Hilbert space">Hilbert space</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Multilinear_algebra" title="Multilinear algebra">Multilinear algebra</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Tensor_algebra" title="Tensor algebra">Tensor algebra</a></li>
<li><a href="/wiki/Exterior_algebra" title="Exterior algebra">Exterior algebra</a></li>
<li><a href="/wiki/Symmetric_algebra" title="Symmetric algebra">Symmetric algebra</a></li>
<li><a href="/wiki/Geometric_algebra" title="Geometric algebra">Geometric algebra</a>&nbsp;(<a href="/wiki/Multivector" title="Multivector">Multivector</a>)</li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Topic lists</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/List_of_abstract_algebra_topics" title="List of abstract algebra topics">Abstract algebra</a></li>
<li><a href="/wiki/Outline_of_algebraic_structures" title="Outline of algebraic structures">Algebraic structures</a></li>
<li><a href="/wiki/List_of_group_theory_topics" title="List of group theory topics">Group theory</a></li>
<li><a href="/wiki/List_of_linear_algebra_topics" title="List of linear algebra topics">Linear algebra</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Glossaries</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Glossary_of_linear_algebra" class="mw-redirect" title="Glossary of linear algebra">Linear algebra</a></li>
<li><a href="/wiki/Glossary_of_field_theory" title="Glossary of field theory">Field theory</a></li>
<li><a href="/wiki/Glossary_of_ring_theory" title="Glossary of ring theory">Ring theory</a></li>
<li><a href="/wiki/Glossary_of_order_theory" title="Glossary of order theory">Order theory</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Related</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Mathematics" title="Mathematics">Mathematics</a></li>
<li><a href="/wiki/History_of_algebra" title="History of algebra">History of algebra</a></li></ul>
</div></td></tr><tr><td class="navbox-abovebelow" colspan="2" style="font-weight:bold;"><div>
<ul><li><img alt="Category" src="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png" decoding="async" title="Category" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x" data-file-width="36" data-file-height="31"> <a href="/wiki/Category:Algebra" title="Category:Algebra">Category</a></li>
<li><img alt="Portal" src="//upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/16px-Portal-puzzle.svg.png" decoding="async" title="Portal" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/24px-Portal-puzzle.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/32px-Portal-puzzle.svg.png 2x" data-file-width="32" data-file-height="28"> <a href="/wiki/Portal:Mathematics" title="Portal:Mathematics">Mathematics portal</a></li>
<li><img alt="Wikibooks page" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikibooks-logo.svg/16px-Wikibooks-logo.svg.png" decoding="async" title="Wikibooks page" width="16" height="16" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikibooks-logo.svg/24px-Wikibooks-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikibooks-logo.svg/32px-Wikibooks-logo.svg.png 2x" data-file-width="300" data-file-height="300"> Wikibooks
<ul><li><a href="https://en.wikibooks.org/wiki/Algebra" class="extiw" title="wikibooks:Algebra">Elementary</a></li>
<li><a href="https://en.wikibooks.org/wiki/Linear_Algebra" class="extiw" title="wikibooks:Linear Algebra">Linear</a></li>
<li><a href="https://en.wikibooks.org/wiki/Abstract_Algebra" class="extiw" title="wikibooks:Abstract Algebra">Abstract</a></li></ul></li>
<li><img alt="Wikiversity page" src="//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Wikiversity-logo.svg/16px-Wikiversity-logo.svg.png" decoding="async" title="Wikiversity page" width="16" height="13" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Wikiversity-logo.svg/24px-Wikiversity-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/91/Wikiversity-logo.svg/32px-Wikiversity-logo.svg.png 2x" data-file-width="1000" data-file-height="800"> <a href="https://en.wikiversity.org/wiki/Linear_algebra" class="extiw" title="wikiversity:Linear algebra">Wikiversity</a>
<ul><li><a href="https://en.wikiversity.org/wiki/Linear_algebra" class="extiw" title="wikiversity:Linear algebra">Linear</a></li>
<li><a href="https://en.wikiversity.org/wiki/Algebraic_structures" class="extiw" title="wikiversity:Algebraic structures">Abstract</a></li></ul></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw1262
Cached time: 20200802155319
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.784 seconds
Real time usage: 1.163 seconds
Preprocessor visited node count: 4505/1000000
Post‐expand include size: 69591/2097152 bytes
Template argument size: 5664/2097152 bytes
Highest expansion depth: 14/40
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 71899/5000000 bytes
Lua time usage: 0.254/10.000 seconds
Lua memory usage: 5.58 MB/50 MB
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  663.423      1 -total
 33.74%  223.818      1 Template:Reflist
 18.11%  120.117      5 Template:Citation
 14.79%   98.094      1 Template:MacTutor
 11.03%   73.202     10 Template:Cite_book
  9.32%   61.848      2 Template:Citation_needed
  8.42%   55.863      1 Template:Isbn
  8.13%   53.962      1 Template:Short_description
  7.78%   51.619      2 Template:Fix
  7.29%   48.368      3 Template:Sister_project
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:125280-0!canonical!math=5 and timestamp 20200802155318 and revision id 969667138
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;"></noscript></div><div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Matrix_multiplication&amp;oldid=969667138">https://en.wikipedia.org/w/index.php?title=Matrix_multiplication&amp;oldid=969667138</a>"</div>
		
	</body>
